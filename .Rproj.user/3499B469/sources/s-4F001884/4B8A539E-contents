
# Contact: Maya Mathur (mmathur@stanford.edu)


############################### SET UP ###############################

rm(list=ls())

##### Set your directories here #####
# these need to match the directories in data_prep.R
# location of code
code.dir = "~/Dropbox/Personal computer/Independent studies/Uncanny Valley III (UV3)/Qualtrics Mousetracker (OSF)/R analysis code"

# location of specialized helper fns only used for this validation study
# and probably not useful for others
special.code.dir = "~/Dropbox/Personal computer/Independent studies/Uncanny Valley III (UV3)/Qualtrics Mousetracker (OSF)/Validation study"

# location of raw Qualtrics data
data.dir = "~/Dropbox/Personal computer/Independent studies/Uncanny Valley III (UV3)/Qualtrics Mousetracker (OSF)/Validation study/Data"

# where to save key
key.dir = "~/Dropbox/Personal computer/Independent studies/Uncanny Valley III (UV3)/Qualtrics Mousetracker (OSF)/Validation study"

# where to save results
results.dir = "~/Dropbox/Personal computer/Independent studies/Uncanny Valley III (UV3)/Qualtrics Mousetracker (OSF)/Validation study/Results"

# get code
setwd(code.dir)
source("general_helper.R")
setwd(special.code.dir)
source("specialized_helper.R")

# read in data prepped by data_prep.R
setwd(data.dir)
# long data
l = read.csv("long_data_prepped.csv")
nrow(l) # should be n * number of faces
# wide data
d = read.csv("wide_data_prepped.csv")
nrow(d)  # should be number of subjects

# load xl, yl, and tl subject lists for making plots
load("xl_subject_lists.RData")
load("yl_subject_lists.RData")
load("tl_subject_lists.RData")

# number of experimental stimuli
( n.stim = length( unique( l$stim.name ) ) )

# code ambiguous and non-ambiguous stimuli
l$confusing = 0
# final 5 faces were in UV, so confusing
l$confusing[ l$stim.name %in% paste( "face.", 6:10, sep="" ) ] = 1
l$confusing = as.factor(l$confusing)
table(l$confusing, l$stim.name)


  
####################### TRIAL-LEVEL DESCRIPTIVE STATS #######################

##### Timing and Latencies #####
# average sampling frequency of coordinates
time.diffs = unlist( lapply( tl, function(list) lapply( list, function(x) diff( unlist(x) ) ) ) )
summary(time.diffs)

# average latency 
# collapse all subjects' latencies since we just want the grand mean
lats = paste( d$latency, collapse="a" )
lats = as.numeric( strsplit( lats, "a" )[[1]] )
summary(lats)

# reaction times in ms (save now before standardizing the variable)
rxnt.ms = l$rxnt

##### Alerts #####
# read in key made during data prep
setwd(key.dir)
key = read.csv("autogenerated_stimulus_vs_url_key.csv")
alerts = describe_alerts( dat = d,
                          n.stim = n.stim,
                          key = key )

# report these in paper
table(alerts$n.alerts.by.trial)
table(alerts$alerts.by.trial)
alerts$ever.alerts


##### Window Sizes #####

# don't need to keep subjects separate for this one
wheights = paste( d$windowHeight, collapse = "a" )
wheights = as.numeric( unlist( strsplit( wheights, "a" ) ) )

wwidths = paste( d$windowWidth, collapse = "a" )
wwidths = as.numeric( unlist( strsplit( wwidths, "a" ) ) )

# report in paper: time.diffs, lats, both alert things above, window summaries


####################### SUBJECT-LEVEL DESCRIPTIVE STATS #######################


##### Browser and OS #####
table(d$browser_Browser)

d$Browser = unlist( lapply( strsplit( as.character(d$browser_Browser), " "), 
                          FUN = function(x) x[1] ) )

d$`Operating system` = unlist( lapply( strsplit( as.character(d$browser_Operating.System), " "), 
                            FUN = function(x) x[1] ) )
d$`Operating system`[ d$`Operating system` == "CrOS" ] = "Chrome OS"


##### Demographics #####

# recode sex
d$Female = rep( NA, nrow(d) )
d$Female[ d$sex == "Female" ] = 1
d$Female[ d$sex == "Male" ] = 0

names(d)[ names(d) == "age" ] = "Age"
names(d)[ names(d) == "educ" ] = "Education"

# recode race
d$`Black/African American` = grepl( "Black/African American", d$race )
d$`Caucasian` = grepl( "Caucasian", d$race )
d$`Native American` = grepl( "Native American", d$race )
d$`East Asian` = grepl( "East Asian", d$race )
d$`Hispanic` = grepl( "Hispanic", d$race )
d$`Middle Eastern` = grepl( "Middle Eastern", d$race )
d$`Southeast Asian` = grepl( "Southeast Asian", d$race )
d$`South Asian` = grepl( "South Asian", d$race )

library(tableone)
vars = c("Browser",
         "Operating system",
         "Female",
         "Age",
         "Education",
         "Black/African American",
         "Caucasian",
         "Native American",
         "East Asian",
         "Hispanic",
         "Middle Eastern",
         "Southeast Asian",
         "South Asian")
table1 = CreateTableOne( data = d[ , names(d) %in% vars] )
setwd(results.dir)
write.csv(table1, "table1.csv")


####################### FIT GEE MODELS #######################

##### Standardize the continuous variables for easier interpretation #####
continuous.outcomes = c("xdev", "area", "speed", "rxnt")

l[,continuous.outcomes] = apply( l[,continuous.outcomes],
                                 2,
                                  function(x) standardize(as.numeric(x)) )

# the violin plot function also does this internally

# max x-deviation
library(geepack)
m.xdev = geeglm( xdev ~ confusing * weird.scaling * wts, 
            data = l, 
            id = ResponseId,
            corstr = "exchangeable" )
summary(m.xdev)

# area
m.area = geeglm( area ~ confusing * weird.scaling * wts, 
            data = l, 
            id = ResponseId,
            corstr = "exchangeable" )
summary(m.area)

# reaction time
m.rxnt = geeglm( rxnt ~ confusing * weird.scaling * wts, 
            data = l, 
            id = ResponseId,
            corstr = "exchangeable" )
summary(m.rxnt)

# speed
m.speed = geeglm( speed ~ confusing * weird.scaling * wts, 
            data = l, 
            id = ResponseId,
            corstr = "exchangeable" )
summary(m.speed)


# x-flips
m.xflips = geeglm( xflips ~ confusing * weird.scaling * wts, 
            data = l, 
            id = ResponseId,
            family = poisson,
            corstr = "exchangeable" )
summary(m.xflips)




####################### GEE MODELS: COMPUTING SYSTEM EFFECTS #######################

# we are going to exclude some rare categories, so copy the dataset
l2 = l

##### Create the Browser and OS Variables #####
names(l2)[ names(l2) == "browser_Browser" ] = "browser"

l2$OS = unlist( lapply( strsplit( as.character(l2$browser_Operating.System), " "), 
                function(x) x[1] ) )
l2$OS[ l2$OS == "CrOS" ] = "Chrome OS"
# make Windows the default level
l2$OS = factor( l2$OS, levels = rev( levels( as.factor(l2$OS) ) ) )


# exclude the very rare categories
l2 = l2[ l2$browser != "Edge", ]
l2 = l2[ l2$OS %in% c("Macintosh", "Windows"), ]
l2 = droplevels(l2)


##### Fit All 5 Models #####
# fit all 5 models and save the interaction coefficients of interest
outcomes = c("xdev", "area", "rxnt", "speed", "xflips")

for ( i in 1:length(outcomes) ) {
  
  family = "gaussian"
  if ( outcomes[i] == "xflips" ) family = "poisson"
  
  m = geeglm( l2[[ outcomes[i] ]] ~ confusing * weird.scaling * wts + confusing*browser + confusing*OS, 
                data = l2, 
                id = ResponseId,
                family = family,
                corstr = "exchangeable" )
  
  row = data.frame( outcome = outcomes[i],
                    
                    bhats = c( coef(m)["confusing1:browserFirefox"],
                               coef(m)["confusing1:OSMacintosh"] ),
                    pvals = c( coef(summary(m))["confusing1:browserFirefox", "Pr(>|W|)"],
                               coef(summary(m))["confusing1:OSMacintosh", "Pr(>|W|)"] ) )
  
  if ( i == 1 ) computing.res = row
  
  else computing.res = rbind( computing.res, row )
}

browser.coefs = computing.res$bhats[ grepl( "Firefox", row.names(computing.res) ) == TRUE ]
browser.pvals = computing.res$pvals[ grepl( "Firefox", row.names(computing.res) ) == TRUE ]

OS.coefs = computing.res$bhats[ grepl( "Macintosh", row.names(computing.res) ) == TRUE ]
OS.pvals = computing.res$pvals[ grepl( "Macintosh", row.names(computing.res) ) == TRUE ]


####################### TRAJECTORY PLOTS FOR 1 SUBJECT #######################

# go through first few subject and show their trajectories for every face
show.animations = TRUE
how.many = 1

# make list of plots for this subject (1 per face)
plot.list = list()

# go through the first 5 subjects' trajectories as an animation
if ( show.animations == TRUE ) {
  for ( i in 1:how.many ) {
    #id = i
    
    id=5
    for ( f in 1:n.stim ){
      plot.list[[f]] = plot_vs_ideal( x = xl[[id]][[f]],
                                      y = yl[[id]][[f]],
                                      title = paste( "Stimulus ", f, sep="" ) )
    }
    
    library(gridExtra)
    nCol = floor(sqrt( length(plot.list)))
    do.call("grid.arrange", c(plot.list, ncol=nCol))
    
    # give user time to look at plot before showing the next one
    if( how.many > 1 ) Sys.sleep(6)
  }
}


##### For Figure 2 #####

setwd(results.dir)
setwd("Subject 1 plots")

for ( i in 1:length(plot.list) ) {
  string = paste( "stimulus_", i, "_trajectory.pdf", sep="" )
  ggsave(filename = string, plot.list[[i]], width = 4, height = 4)
}



####################### FIGURE 2: VIOLIN PLOTS WITH GEE REGRESSION RESULTS #######################

# p-value and beta-hats are from GEE with robust SEs 
#  and exchangeable working structure by subject (not face b/c can't
#  specify two variables)

library(ggplot2)

plot.list = list()
mediators = c( "xflips", "area", "xdev", "speed", "rxnt" )

for ( f in 1:length(mediators) ) {
  plot.list[[f]] = my_violins(mediators[f])
}

library(gridExtra)
nCol = 3
do.call("grid.arrange", c(plot.list, ncol=nCol))
# save manually via Export (10 x 7)



####################### SENSITIVITY ANALYSIS: EXCLUDE ANY IFFY SUBJECTS #######################

temp = l[ l$wts == 0 & l$weird.scaling == 0, ]
length(unique(temp$ResponseId))  # n = 103


# max x-deviation
library(geepack)
m.xdev2 = geeglm( temp[["xdev"]] ~ confusing, 
                  data = temp, 
                  id = ResponseId,
                  corstr = "exchangeable" )
summary(m.xdev2)

# area
m.area2 = geeglm( temp[["area"]] ~ confusing, 
                  data = temp, 
                  id = ResponseId,
                  corstr = "exchangeable" )
summary(m.area2)

# reaction time
m.rxnt2 = geeglm( temp[["rxnt"]] ~ confusing, 
                  data = temp, 
                  id = ResponseId,
                  corstr = "exchangeable" )
summary(m.rxnt2)

# speed
m.speed2 = geeglm( temp[["speed"]] ~ confusing, 
                   data = temp, 
                   id = ResponseId,
                   corstr = "exchangeable" )
summary(m.speed2)


# x-flips
m.xflips2 = geeglm( temp[["xflips"]] ~ confusing, 
                    data = temp, 
                    id = ResponseId,
                    family = poisson,
                    corstr = "exchangeable" )
summary(m.xflips2)




####################### SAVE OBJECTS #######################

# write all other R objects as well
setwd(results.dir)
save.image( file = "all_analysis_objects.RData")
